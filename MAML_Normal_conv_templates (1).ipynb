{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "1bs6VqbdKPMv",
    "outputId": "c2a5133b-56db-4746-8294-189dbd64c5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmeta in ./.local/lib/python3.6/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (4.43.0)\n",
      "Requirement already satisfied: torch<1.5.0,>=1.4.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (1.4.0)\n",
      "Requirement already satisfied: h5py~=2.9.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (2.9.0)\n",
      "Requirement already satisfied: torchvision<0.6.0,>=0.5.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (0.5.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchmeta) (2.18.4)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in ./.local/lib/python3.6/site-packages (from torchmeta) (7.0.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from h5py~=2.9.0->torchmeta) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtdgJCNHKYrj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchmeta.modules import (MetaModule,MetaConv2d,MetaBatchNorm2d,MetaSequential,MetaLinear)\n",
    "from torchmeta.modules.utils import get_subdict\n",
    "from collections import OrderedDict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 14 18:50:53 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 41%   75C    P2   225W / 250W |   4603MiB / 10989MiB |     89%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 28%   38C    P2    65W / 250W |    967MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    35W / 250W |   1852MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 37%   65C    P2   249W / 250W |   4603MiB / 10989MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    14W / 250W |     10MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    31W / 250W |   2981MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 38%   67C    P2   246W / 250W |   4603MiB / 10989MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 33%   52C    P2    93W / 250W |   8169MiB / 10989MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     17378      C   python3                                     4593MiB |\n",
      "|    1      9458      C   python3                                      957MiB |\n",
      "|    2      8020      C   python3                                      979MiB |\n",
      "|    2     20908      C   /usr/bin/python3                             859MiB |\n",
      "|    3     16954      C   python3                                     4593MiB |\n",
      "|    5      6361      C   /usr/bin/python3                            2965MiB |\n",
      "|    6     17184      C   python3                                     4593MiB |\n",
      "|    7     20908      C   /usr/bin/python3                            8155MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKXW6vOuLVPi"
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, **kwargs):\n",
    "  return MetaSequential(OrderedDict([\n",
    "      ('conv', MetaConv2d(in_channels, out_channels, **kwargs)),\n",
    "      ('norm', nn.BatchNorm2d(out_channels, momentum=1.,\n",
    "          track_running_stats=False)),\n",
    "      ('relu', nn.ReLU()),\n",
    "      ('pool', nn.MaxPool2d(2))\n",
    "  ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDQ4SJQXSWzs"
   },
   "outputs": [],
   "source": [
    "class TemplateBank(nn.Module):\n",
    "  def __init__(self,num_templates,input_channels,output_channels, kernel_size):\n",
    "    super(TemplateBank,self).__init__()\n",
    "    self.coefficients_shape=(num_templates,1,1,1,1)\n",
    "    #the templates are convolutions windows, we n_templates of the same size in the bank\n",
    "    templates=[torch.Tensor(input_channels,output_channels,kernel_size,kernel_size) for i in range(num_templates)]\n",
    "    #stack the tensors, same form but now usable for pytorch\n",
    "    self.templates=nn.Parameter(torch.stack(templates))\n",
    "  def forward(self,coefficients):\n",
    "    #print(\"Linear combination of the templates\",(self.templates*coefficients).sum(0))\n",
    "    #linear combination\n",
    "    return (self.templates*coefficients).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWFkbiZuSOVo"
   },
   "outputs": [],
   "source": [
    "class SConv2d(MetaModule):\n",
    "  def __init__(self,bank,stride=1,padding=1):\n",
    "    super(SConv2d,self).__init__()\n",
    "    self.stride , self.padding, self.bank= stride, padding, bank\n",
    "    #soft parameter in front of the templates, determine by the shape of the bank\n",
    "    self.coefficients=nn.Parameter(torch.zeros(bank.coefficients_shape))\n",
    "  def forward(self,input,params=None):\n",
    "    # these are the convolution parameters, we multiplied the linear coef to the templates\n",
    "    #it's one tensor, create by the forward method of bank\n",
    "    coeffs=OrderedDict(params)[\"coefficients\"]\n",
    "    \n",
    "    parameters=self.bank(coeffs)\n",
    "    #Performs a normal convolutions with the linear combination of the templates\n",
    "    return F.conv2d(input,parameters,stride=self.stride,padding=self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cm8UAo2LXwM"
   },
   "outputs": [],
   "source": [
    "class conv_block_soft(MetaModule):\n",
    "  def __init__(self,input_channels,output_channels,bank=None):\n",
    "    super(conv_block_soft,self).__init__()\n",
    "    self.bank=bank\n",
    "    self.conv1=SConv2d(self.bank)\n",
    "    self.bn1=nn.BatchNorm2d(output_channels)\n",
    "    self.relu=nn.ReLU(inplace=True)\n",
    "    self.maxpool=nn.MaxPool2d(2)\n",
    "  def forward(self,x,params=None):\n",
    "    x=self.conv1(x,params=get_subdict(params,\"conv1\"))\n",
    "    x=self.bn1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.maxpool(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dcR-ZVKS_lG"
   },
   "outputs": [],
   "source": [
    "class SConvNet(MetaModule):\n",
    "  def __init__(self,num_templates,num_classes,in_channels,hidden_size=64,feature_size=64):\n",
    "    super(SConvNet,self).__init__()\n",
    "    print(\"SConvNet, Templates:\",num_templates)\n",
    "    layers_per_bank=2*(4-1) #find out why\n",
    "  \n",
    "    self.conv_3x3=MetaConv2d(in_channels,hidden_size,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "    self.bank=TemplateBank(num_templates,hidden_size,hidden_size,3)\n",
    "    self.block1=conv_block_soft(hidden_size,hidden_size,self.bank)\n",
    "    self.block2=conv_block_soft(hidden_size,hidden_size,self.bank)\n",
    "    self.block3=conv_block_soft(hidden_size,hidden_size,self.bank)\n",
    "    self.block4=conv_block_soft(hidden_size,hidden_size,self.bank)\n",
    "    self.classifier=MetaLinear(feature_size,num_classes,bias=True)\n",
    "    \n",
    "    #initialisations\n",
    "    coefficient_inits = torch.zeros((int(layers_per_bank),int(num_templates),1,1,1,1))\n",
    "    nn.init.orthogonal_(coefficient_inits) # very important\n",
    "    sconv_group=[]\n",
    "    for name,module in self.named_modules():\n",
    "        if isinstance(module,SConv2d):\n",
    "          sconv_group.append((name,module))\n",
    "    for j,(name,module) in enumerate(sconv_group):\n",
    "        module.coefficients.data=coefficient_inits[j]\n",
    "    \n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "      elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "      elif isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "  def forward(self,x,params=None):\n",
    "    x=self.conv_3x3(x,params=get_subdict(params,\"conv_3x3\"))\n",
    "    x=self.block1(x,params=get_subdict(params,\"block1\"))\n",
    "    x=self.block2(x,params=get_subdict(params,\"block2\"))\n",
    "    x=self.block3(x,params=get_subdict(params,\"block3\"))\n",
    "    x=self.block4(x,params=get_subdict(params,\"block4\"))\n",
    "    \n",
    "    x=x.view((x.size(0), -1))\n",
    "\n",
    "    x=self.classifier(x,params=get_subdict(params,\"classifier\"))\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HekC-_DDKxWq"
   },
   "outputs": [],
   "source": [
    "class MetaConvModel(MetaModule):\n",
    "  def __init__(self,in_channels,out_features,hidden_size=64,feature_size=64):\n",
    "    super(MetaConvModel,self).__init__()\n",
    "    self.in_channels=in_channels\n",
    "    self.out_features=out_features\n",
    "    self.hidden_size=hidden_size\n",
    "    self.feature_size=feature_size\n",
    "\n",
    "    self.features = MetaSequential(OrderedDict([                                         \n",
    "    ('layer1', conv_block(in_channels, hidden_size, kernel_size=3,\n",
    "                          stride=1, padding=1, bias=True)),\n",
    "    ('layer2', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
    "                          stride=1, padding=1, bias=True)),\n",
    "    ('layer3', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
    "                          stride=1, padding=1, bias=True)),\n",
    "    ('layer4', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
    "                          stride=1, padding=1, bias=True))\n",
    "    ]))\n",
    "    self.classifier = MetaLinear(feature_size, out_features, bias=True)\n",
    "  def forward(self, inputs, params=None):\n",
    "    features = self.features(inputs, params=get_subdict(params, 'features'))\n",
    "    features = features.view((features.size(0), -1))\n",
    "    logits = self.classifier(features, params=get_subdict(params, 'classifier'))\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqKBDB0lvXFI"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFikt-FivngY"
   },
   "outputs": [],
   "source": [
    "class MAML(object):\n",
    "  def __init__(self,model,optimizer=None,step_size=0.1,loss_function=F.cross_entropy):\n",
    "    #metamodel, the neural net for the tasks\n",
    "    self.model=model\n",
    "\n",
    "    self.optimizer=optimizer\n",
    "    #the step size could be meta-learnable, but for now we put it fixed\n",
    "    self.step_size=torch.tensor(step_size,dtype=torch.float32,requires_grad=False)\n",
    "    self.loss_function=loss_function\n",
    "    self.params_dict=OrderedDict(self.model.named_parameters())\n",
    "  def accuracy(self,logits,targets):\n",
    "    with torch.no_grad():\n",
    "      _,predictions=torch.max(logits,dim=1)\n",
    "      accuracy=torch.mean(predictions.eq(targets).float())\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "  def step(self,batch):\n",
    "    outer_loss=0\n",
    "    #average of accuracy accross tasks for query set\n",
    "    outer_accuracy=0\n",
    "    counter=0\n",
    "    for task_id,task in enumerate(zip(*batch[\"train\"],*batch[\"test\"])):\n",
    "      if counter>5:\n",
    "            break\n",
    "      counter+=1\n",
    "      # the zip is now a array of 25 (one for each task) with 4 columns\n",
    "      # train_inputs, train_target, test_inputs, test_target\n",
    "      #each task in this zip is a batch for a specific task\n",
    "      train_inputs,train_targets=task[0].cuda(),task[1].cuda() #support set\n",
    "      test_inputs,test_targets=task[2].cuda(),task[3].cuda() #querry set\n",
    "      \n",
    "      #don't forget to pass it named_parameters, and shouldn't be an iterator\n",
    "      train_logits=self.model(train_inputs,self.params_dict)#OrderedDict(self.model.named_parameters())\n",
    "      inner_loss=self.loss_function(train_logits,train_targets)\n",
    "      self.model.zero_grad()\n",
    "      #the model will have parameters called meta_params\n",
    "      grads=torch.autograd.grad(inner_loss,self.model.parameters())\n",
    "      \n",
    "      #Updating the parameters for that tast\n",
    "      #this becomes a for loop if we do many training steps inside, default is 1\n",
    "      params=OrderedDict()\n",
    "      i=0\n",
    "      '''for (name,param), grad in zip(self.model.named_parameters(),grads):\n",
    "        #if name in ...:\n",
    "        #find better way to do this\n",
    "        if \"coefficients\" in name:\n",
    "          params[name]=param-self.step_size*grad\n",
    "        else:\n",
    "          params[name]=param'''\n",
    "    \n",
    "      for (name,param), grad in zip(self.model.named_parameters(),grads):\n",
    "            params[name]=param-self.step_size*grad\n",
    "            \n",
    "      \n",
    "      \n",
    "      #this step in the paper is outside the inner loop, we evaluate on query set\n",
    "      #the query set of that task, using the newly learned params (theta i), and updtate the real theta with it\n",
    "      #we can caluclate the loss for each i during each step, so we don't have to remember the theta i\n",
    "      #assign theta i (params) to the model temporarly to evaluate\n",
    "      test_logit=self.model(test_inputs,params=params)\n",
    "\n",
    "      #do we really take the average of accuracy for each task in the batch?\n",
    "      \n",
    "      #!!!! We could add a dictionary to collect the task loss for a specific id.\n",
    "\n",
    "      outer_loss+=self.loss_function(test_logit,test_targets)\n",
    "      outer_accuracy+=self.accuracy(test_logit,test_targets)\n",
    "    \n",
    "    outer_accuracy=float(outer_accuracy)/counter  #float(len(batch[\"train\"][0])) #len of a torch tensor?\n",
    "    #computes gradient\n",
    "    outer_loss.backward()\n",
    "    #the optimizer should already be \"loaded\" with the model's params\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return outer_loss.detach(),outer_accuracy\n",
    "\n",
    "  def train(self,dataloader,max_batches=500):\n",
    "    num_batches=0\n",
    "    for batch in dataloader:\n",
    "      if num_batches>=max_batches:\n",
    "        break\n",
    "      l,a=self.step(batch)\n",
    "      print(l,a)\n",
    "      num_batches+=1\n",
    "  def step_evaluate(self,batch):\n",
    "    outer_loss=0\n",
    "    for task in batch:\n",
    "      train_inputs,train_targets=task[\"support\"]\n",
    "      test_inputs,test_targets=task[\"query\"]\n",
    "\n",
    "      train_logits=self.model(train_inputs,params=model.named_parameters())\n",
    "      #don't forget to pass in parameters\n",
    "      inner_loss=self.loss_function(train_logits,train_targets)\n",
    "      self.model.zero_grad()\n",
    "      #the model will have parameters called meta_params\n",
    "      grads=torch.autograd.grad(inner_loss,self.model.meta_params())\n",
    "      params=OrderedDict()\n",
    "      \n",
    "      #Updating the parameters for that tast\n",
    "      for (name,param), grad in zip(model.meta_named_pars(),grads):\n",
    "        params[name]=param-step_size*grad\n",
    "      \n",
    "      #this step in the paper is outside the inner loop, we evaluate on query set\n",
    "      #the query set of that task, using the newly learned params (theta i), and updtate the real theta with it\n",
    "      #we can caluclate the loss for each i during each step, so we don't have to remember the theta i\n",
    "      #assign theta i (params) to the model temporarly to evaluate\n",
    "      test_logits=model(test_inputs,params=params) \n",
    "\n",
    "      outer_accuracy+=self.accuracy(np.argmax(test_logits),test_targets)\n",
    "      outer_loss+=self.loss_function(test_logits,test_targets)\n",
    "    \n",
    "    outer_accuracy=float(outer_accuracy)/float(len(batch)) #len of torch tensor?\n",
    "    #we don't update the meta_params when evaluating\n",
    "    return outer_loss,outer_accuracy\n",
    "  def evaluate(self,dataloader,max_batches=500):\n",
    "    mean_outer_loss,mean_accuracy,count= 0., 0., 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "      if num_batches>=max_batches:\n",
    "        break\n",
    "      outer_loss,outer_accuracy=self.step_evaluate(batch)\n",
    "\n",
    "      mean_outer_loss+=outer_loss\n",
    "      mean_accuracy+=outer_accuracy\n",
    "      count+=1\n",
    "    \n",
    "    return float(mean_outer_loss)/float(count) , float(mean_accuracy)/float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okha9H4YwkBa"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, gammas, schedule, loss):\n",
    "  lr = args.learning_rate\n",
    "  assert len(gammas) == len(schedule), \"length of gammas and schedule should be equal\"\n",
    "  for (gamma, step) in zip(gammas, schedule):\n",
    "    if (epoch >= step): lr = lr * gamma\n",
    "    else: break\n",
    "  for param_group in optimizer.param_groups: param_group['lr'] = lr\n",
    "  return lr\n",
    "def group_weight_decay(net, weight_decay, skip_list=()):\n",
    "  decay, no_decay = [], []\n",
    "  for name, param in net.named_parameters():\n",
    "    if not param.requires_grad: continue\n",
    "    if sum([pattern in name for pattern in skip_list]) > 0: no_decay.append(param)\n",
    "    else: decay.append(param)\n",
    "  return [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': weight_decay}]\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "  if len(target.shape) > 1: return torch.tensor(1), torch.tensor(1)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul_(100.0 / batch_size))\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9z4S0Tnwmo4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MeOdIILCvxb7"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orKOUwVYvnwi"
   },
   "outputs": [],
   "source": [
    "from torchmeta.datasets import Omniglot, MiniImagenet\n",
    "from torchmeta.transforms import ClassSplitter, Categorical, Rotation\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from torchmeta.utils.data import BatchMetaDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caOvgyt1vnKg"
   },
   "outputs": [],
   "source": [
    "#-------------HyperParameters----------------------\n",
    "num_shots=5\n",
    "num_ways=5\n",
    "num_shots_test=5\n",
    "batch_size=128\n",
    "num_workers=1\n",
    "\n",
    "#optimization\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "schedule=[60,120,160]\n",
    "gammas=[0.2,0.2,0.2]\n",
    "#regularization\n",
    "decay=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "e366fb8dadcf40ba92f1ce10e6861321",
      "1662c469bf3344af92ba9ae2bcf4227d",
      "c93c06da048840fe93036ffeefb552cd",
      "250cb4921a854c6ab44f0e5f67d080d6",
      "1a934b8a0c9047d4bfd22a88f469f5eb",
      "f48dc550e8304173b3d6fa2738e09df8",
      "64d13f50950243adb5ef056e5b10be5a",
      "6e6b59e6133d4f72a78f7e1cfde7f2d2"
     ]
    },
    "colab_type": "code",
    "id": "0Owraf9Ev9Vx",
    "outputId": "bdb217b6-edeb-4267-d6b8-b52ca4cb302e"
   },
   "outputs": [],
   "source": [
    "dataset_transform = ClassSplitter(shuffle=True,\n",
    "                                      num_train_per_class=num_shots,\n",
    "                                      num_test_per_class=num_shots_test)\n",
    "transform = Compose([Resize(84), ToTensor()])\n",
    "\n",
    "meta_train_dataset = MiniImagenet(\"data\",\n",
    "                                  transform=transform,\n",
    "                                  target_transform=Categorical(num_ways),\n",
    "                                  num_classes_per_task=num_ways,\n",
    "                                  meta_train=True,\n",
    "                                  dataset_transform=dataset_transform,\n",
    "                                  download=True)\n",
    "meta_val_dataset = MiniImagenet(\"data\",\n",
    "                                transform=transform,\n",
    "                                target_transform=Categorical(num_ways),\n",
    "                                num_classes_per_task=num_ways,\n",
    "                                meta_val=True,\n",
    "                                dataset_transform=dataset_transform)\n",
    "meta_test_dataset = MiniImagenet(\"data\",\n",
    "                                  transform=transform,\n",
    "                                  target_transform=Categorical(num_ways),\n",
    "                                  num_classes_per_task=num_ways,\n",
    "                                  meta_test=True,\n",
    "                                  dataset_transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tALoQRrAwAbZ"
   },
   "outputs": [],
   "source": [
    "dataset_transform = ClassSplitter(shuffle=True,\n",
    "                                      num_train_per_class=num_shots,\n",
    "                                      num_test_per_class=num_shots_test)\n",
    "class_augmentations = [Rotation([90, 180, 270])]\n",
    "transform = Compose([Resize(28), ToTensor()])\n",
    "\n",
    "meta_train_dataset = Omniglot(\"data\",\n",
    "                              transform=transform,\n",
    "                              target_transform=Categorical(num_ways),\n",
    "                              num_classes_per_task=num_ways,\n",
    "                              meta_train=True,\n",
    "                              class_augmentations=class_augmentations,\n",
    "                              dataset_transform=dataset_transform,\n",
    "                              download=True)\n",
    "meta_val_dataset = Omniglot(\"data\",\n",
    "                            transform=transform,\n",
    "                            target_transform=Categorical(num_ways),\n",
    "                            num_classes_per_task=num_ways,\n",
    "                            meta_val=True,\n",
    "                            class_augmentations=class_augmentations,\n",
    "                            dataset_transform=dataset_transform)\n",
    "meta_test_dataset = Omniglot(\"data\",\n",
    "                             transform=transform,\n",
    "                             target_transform=Categorical(num_ways),\n",
    "                             num_classes_per_task=num_ways,\n",
    "                             meta_test=True,\n",
    "                             dataset_transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ld2PmZPJwBjU"
   },
   "outputs": [],
   "source": [
    "meta_train_dataloader = BatchMetaDataLoader(meta_train_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=num_workers,\n",
    "                                                pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "HDycIkkrwBgT",
    "outputId": "3064c813-d8fa-4f81-9d6f-48fe46f384bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test'])\n",
      "2\n",
      "2\n",
      "128\n",
      "25\n",
      "3\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f9a3f586ef0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dominic/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dominic/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    }
   ],
   "source": [
    "#exploring dataset\n",
    "#train is the support set, test is the querry set\n",
    "num_batches=0\n",
    "for batch in meta_train_dataloader:\n",
    "  if num_batches>=1:\n",
    "    break\n",
    "  num_batches+=1\n",
    "  print(batch.keys())\n",
    "  print(len(batch[\"train\"]))\n",
    "  print(len(batch[\"test\"]))\n",
    "  print(len(batch[\"train\"][0]))\n",
    "  print(len(batch[\"train\"][0][0]))\n",
    "  b=batch\n",
    "\n",
    "  # one data point\n",
    "  print(len(batch[\"train\"][0][0][0]))\n",
    "  #-------------\n",
    "  \n",
    "  print(len(batch[\"train\"][0][0][0][0]))\n",
    "\n",
    "  # batch[\"train\"] contains (inputs,targets)\n",
    "  # for batch[\"train\"][0], it's a batch of 25 tasks, each containing a batch \n",
    "  #of data for the specific tast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iusxMwYswBdW"
   },
   "outputs": [],
   "source": [
    "out_features=5\n",
    "hidden_size=64\n",
    "loss_function=torch.nn.CrossEntropyLoss().cuda()\n",
    "in_channels=3 #1 for omniglot\n",
    "bank_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kXMWWf2nwBaP",
    "outputId": "102cf7fc-3d62-44fc-8d77-dd27f03bac94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SConvNet, Templates: 4\n"
     ]
    }
   ],
   "source": [
    "ModelConvMiniImagenet=SConvNet(bank_size,out_features,in_channels,feature_size=5*5*hidden_size).cuda()\n",
    "params = group_weight_decay(ModelConvMiniImagenet, decay, ['coefficients'])\n",
    "optimizer=torch.optim.SGD(params, learning_rate, momentum=momentum, nesterov=(momentum > 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6bQC-dKRDjE"
   },
   "outputs": [],
   "source": [
    "no_temp_model=MetaConvModel(3,5,feature_size=5*5*hidden_size).cuda()\n",
    "#params = group_weight_decay(no_temp_model, decay, ['coefficients'])\n",
    "optimizer=torch.optim.Adam(no_temp_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "3Mpm7w93RblU",
    "outputId": "808dad3e-f310-49be-f781-2ff425d77138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8003e-01, -6.6278e-01,  4.4539e-01, -6.4611e-01,  5.5670e-01],\n",
       "        [-5.3446e-01,  5.7241e-01, -8.0421e-01, -2.4264e-01,  1.5255e-02],\n",
       "        [-3.6964e-01,  7.6982e-01, -4.6636e-01, -9.1376e-02,  2.4605e-01],\n",
       "        [-1.7285e-01, -7.5022e-01,  4.8225e-01, -4.9210e-01, -3.7648e-01],\n",
       "        [-5.9095e-02,  3.0657e-01, -3.5983e-01, -1.0320e-01,  3.9580e-01],\n",
       "        [-2.2635e-01, -3.9382e-01, -6.9858e-02,  9.3446e-02, -7.4817e-03],\n",
       "        [ 5.0721e-01,  9.7340e-01, -2.0405e-01, -6.2920e-01,  2.2934e-01],\n",
       "        [-2.7097e-01, -3.7709e-01,  4.6626e-02, -5.4277e-01, -1.8947e-01],\n",
       "        [ 2.2131e-02,  4.7656e-01, -4.5332e-01, -4.9635e-01,  9.7650e-01],\n",
       "        [-3.1347e-02,  4.8161e-01,  1.1267e-01, -3.5136e-01,  6.1019e-01],\n",
       "        [ 1.1792e-01,  8.0014e-01, -2.7295e-01, -1.9375e-01, -2.2388e-01],\n",
       "        [-2.8205e-01,  1.1113e+00, -1.3583e-01, -7.0185e-01, -3.6855e-02],\n",
       "        [ 3.5178e-01,  7.8203e-01, -1.6053e-01, -7.4662e-01, -4.5009e-03],\n",
       "        [ 2.4304e-01,  3.6571e-01, -1.5341e-01, -1.4983e-01, -1.5458e-01],\n",
       "        [-3.4745e-01,  1.0310e+00, -5.2269e-01, -3.7473e-01,  1.9421e-01],\n",
       "        [-2.2247e-01,  2.0863e-01, -1.3925e-01, -4.3273e-01,  1.7265e-01],\n",
       "        [ 1.5380e-01,  2.0930e-02, -6.7753e-01, -2.1267e-02,  2.0214e-01],\n",
       "        [-2.0579e-01,  4.5149e-01, -3.3473e-02, -1.5983e-01,  6.2497e-02],\n",
       "        [ 2.3127e-01,  4.8010e-01,  1.2559e-01, -3.2428e-01,  3.1333e-01],\n",
       "        [ 3.9448e-02,  1.2538e+00, -7.2562e-01, -3.8500e-01, -2.1030e-02],\n",
       "        [ 6.9728e-02,  9.7348e-01,  3.3183e-01, -3.7334e-01, -2.4344e-01],\n",
       "        [ 1.7013e-01,  9.1370e-01, -1.0900e-01, -6.9562e-01,  1.8456e-01],\n",
       "        [-2.1657e-01,  1.0597e+00, -1.0896e+00, -4.5277e-01, -4.8529e-01],\n",
       "        [ 4.4664e-01,  5.3344e-01, -2.1526e-01, -4.6212e-01, -8.8815e-02],\n",
       "        [-6.1273e-04,  1.5958e-01, -9.0752e-01, -4.2231e-01,  1.4105e-01]],\n",
       "       device='cuda:5', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_temp_model(b[\"train\"][0][0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "UMW9iuwfwBRg",
    "outputId": "0af6a13e-aae5-4114-e59b-48dad8ae590b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243],\n",
       "        [-0.0229, -0.0186, -0.0140, -0.0125,  0.0243]], device='cuda:4',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=OrderedDict(ModelConvMiniImagenet.named_parameters())\n",
    "ModelConvMiniImagenet(b[\"train\"][0][0].cuda(),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfGxXHxbwBOd"
   },
   "outputs": [],
   "source": [
    "metalearner=MAML(ModelConvMiniImagenet,optimizer,loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "colab_type": "code",
    "id": "4zRC3N7iwBHP",
    "outputId": "eb9fcbc2-542f-45c6-f5e0-0c4455297f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6575, device='cuda:4') 0.19999998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f9a3f586ef0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dominic/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dominic/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6575, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n",
      "tensor(9.6574, device='cuda:4') 0.19999998807907104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ae6d70efb5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_train_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-c757a9a8347b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, max_batches)\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "  metalearner.train(meta_train_dataloader,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pzy_swbFwM06"
   },
   "outputs": [],
   "source": [
    "          state={\n",
    "  'epoch': epoch + 1,\n",
    "  'state_dict': ModelConvMiniImagenet.state_dict(),\n",
    "  'optimizer' : optimizer.state_dict(),\n",
    "}\n",
    "filename=\"maml_paper_implementation_templates.pth.tar\"\n",
    "torch.save(state,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MAML_Normal_conv_templates.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1662c469bf3344af92ba9ae2bcf4227d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a934b8a0c9047d4bfd22a88f469f5eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "250cb4921a854c6ab44f0e5f67d080d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e6b59e6133d4f72a78f7e1cfde7f2d2",
      "placeholder": "",
      "style": "IPY_MODEL_64d13f50950243adb5ef056e5b10be5a",
      "value": " 1083044483/? [01:06&lt;00:00, 16255628.31it/s]"
     }
    },
    "64d13f50950243adb5ef056e5b10be5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6b59e6133d4f72a78f7e1cfde7f2d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c93c06da048840fe93036ffeefb552cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f48dc550e8304173b3d6fa2738e09df8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a934b8a0c9047d4bfd22a88f469f5eb",
      "value": 1
     }
    },
    "e366fb8dadcf40ba92f1ce10e6861321": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c93c06da048840fe93036ffeefb552cd",
       "IPY_MODEL_250cb4921a854c6ab44f0e5f67d080d6"
      ],
      "layout": "IPY_MODEL_1662c469bf3344af92ba9ae2bcf4227d"
     }
    },
    "f48dc550e8304173b3d6fa2738e09df8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
